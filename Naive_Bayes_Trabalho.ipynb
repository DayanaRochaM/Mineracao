{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCQqSJ9O1-hl"
   },
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "<br><br>\n",
    "<strong> Equipe </strong>:\n",
    "1. Cristiano Filho\n",
    "2. Dayana Rocha - 384349\n",
    "\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Respostas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1\n",
    "\n",
    "#### 1.1 Definindo funções a serem utilizadas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLuJObc61-hn"
   },
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "\n",
    "import csv\n",
    " \n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(0, len(dataset)):\n",
    "        \n",
    "        #Substituindo strings por números\n",
    "        \n",
    "        #Buying\n",
    "        if(dataset[i][0] == 'vhigh'):    \n",
    "            dataset[i][0] = 4\n",
    "            \n",
    "        elif(dataset[i][0] == 'high'):    \n",
    "            dataset[i][0] = 3\n",
    "            \n",
    "        elif(dataset[i][0] == 'med'):    \n",
    "            dataset[i][0] = 2\n",
    "            \n",
    "        elif(dataset[i][0] == 'low'):    \n",
    "            dataset[i][0] = 1\n",
    "        \n",
    "        #Maint\n",
    "        if(dataset[i][1] == 'vhigh'):    \n",
    "            dataset[i][1] = 4\n",
    "            \n",
    "        elif(dataset[i][1] == 'high'):    \n",
    "            dataset[i][1] = 3\n",
    "            \n",
    "        elif(dataset[i][1] == 'med'):    \n",
    "            dataset[i][1] = 2\n",
    "            \n",
    "        elif(dataset[i][1] == 'low'):    \n",
    "            dataset[i][1] = 1\n",
    "        \n",
    "        #Doors\n",
    "        if(dataset[i][2] == '5more'):    \n",
    "            dataset[i][2] = 6\n",
    "        \n",
    "        #Persons\n",
    "        if(dataset[i][3] == 'more'):    \n",
    "            dataset[i][3] = 6\n",
    "            \n",
    "        #Lug_boot\n",
    "        if(dataset[i][4] == 'big'):    \n",
    "            dataset[i][4] = 3\n",
    "            \n",
    "        elif(dataset[i][4] == 'med'):    \n",
    "            dataset[i][4] = 2\n",
    "            \n",
    "        elif(dataset[i][4] == 'small'):    \n",
    "            dataset[i][4] = 1\n",
    "            \n",
    "        #Safety\n",
    "        if(dataset[i][5] == 'high'):    \n",
    "            dataset[i][5] = 3\n",
    "            \n",
    "        elif(dataset[i][5] == 'med'):    \n",
    "            dataset[i][5] = 2\n",
    "            \n",
    "        elif(dataset[i][5] == 'low'):    \n",
    "            dataset[i][5] = 1\n",
    "            \n",
    "        #Classes\n",
    "        if(dataset[i][6] == 'vgood'):    \n",
    "            dataset[i][6] = 4\n",
    "            \n",
    "        elif(dataset[i][6] == 'good'):    \n",
    "            dataset[i][6] = 3\n",
    "            \n",
    "        elif(dataset[i][6] == 'acc'):    \n",
    "            dataset[i][6] = 2\n",
    "            \n",
    "        elif(dataset[i][6] == 'unacc'):    \n",
    "            dataset[i][6] = 1\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAwVf9gI1-hv"
   },
   "outputs": [],
   "source": [
    "# Dividir dataset em train e test\n",
    "\n",
    "import random\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpnTFVaE1-hy"
   },
   "outputs": [],
   "source": [
    "# Agrupar linhas por classe\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-v_Ea9J1-h3"
   },
   "outputs": [],
   "source": [
    "# Funções matemáticas que serão utilizadas\n",
    "\n",
    "import math\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNoN5wFz1-h6"
   },
   "outputs": [],
   "source": [
    "# Calcular desvio padrão e média por atributo\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azmVydsH1-h_"
   },
   "outputs": [],
   "source": [
    "# \"Summarizar\" atributos por classes\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSQPtVUl1-iC"
   },
   "outputs": [],
   "source": [
    "# Calcular probabilidade de que um valor de atributo pertença à classe\n",
    "# Função de densidade de probabilidade Gaussiana\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    # No caso em que é zero, atribuir um valor grande para que o resultado se aproxime de zero\n",
    "    if (stdev == 0):\n",
    "        stdev = 10000\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * math.pow(stdev, 2))) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rh4ZvELC1-iF"
   },
   "outputs": [],
   "source": [
    "# Calcular probabilidade de atributo para cada classe\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xa_pAzHa1-iH"
   },
   "outputs": [],
   "source": [
    "# Realizar predição\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIsFljqo1-iJ"
   },
   "outputs": [],
   "source": [
    "# Realizar predição para uma lista \n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAk952EU1-iL"
   },
   "outputs": [],
   "source": [
    "# Calcular precisão da predição\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Algoritmo para realizar predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9d1IxMup1-iV",
    "outputId": "51c57587-1826-43d8-ce35-231cffbb3f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.95096322241682%\n"
     ]
    }
   ],
   "source": [
    "# Arquivo do dataset\n",
    "filename = 'carData.csv'\n",
    "\n",
    "# Lendo arquivo\n",
    "dataset = loadCsv(filename)\n",
    "\n",
    "# Definindo coeficiente para divisão entre dados de treino e teste\n",
    "splitRatio = 0.67\n",
    "\n",
    "# Definindo conjuntos de treino e teste\n",
    "train, test = splitDataset(dataset, splitRatio)\n",
    "\n",
    "# Preparando modelo\n",
    "summaries = summarizeByClass(train)\n",
    "\n",
    "# Testando modelo\n",
    "predictions = getPredictions(summaries, test)\n",
    "\n",
    "# Calculando acurácia\n",
    "accuracy = getAccuracy(test, predictions)\n",
    "print('Accuracy: {0}%'.format(accuracy))\n",
    "\n",
    "firstExpected = [linha[-1] for linha in test]\n",
    "firstPredicted = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIMlDTV1-iZ"
   },
   "source": [
    "## Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.35201401050787%\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Lendo arquivo\n",
    "dataset = loadCsv(\"carData.csv\")\n",
    "\n",
    "# Definindo coeficiente para divisão entre dados de treino e teste\n",
    "splitRatio = 0.67\n",
    "\n",
    "# Separando dados de treino e teste\n",
    "train, test = splitDataset(dataset, splitRatio)\n",
    "\n",
    "# Criando nosso modelo\n",
    "model = GaussianNB()\n",
    "\n",
    "# Treinando modelo\n",
    "trainData = [linha[:-1] for linha in train]\n",
    "trainTarget = [linha[-1] for linha in train]\n",
    "model.fit(trainData, trainTarget)\n",
    "\n",
    "# Fazendo predições\n",
    "testData = [linha[:-1] for linha in test]\n",
    "testTarget = [linha[-1] for linha in test]\n",
    "\n",
    "secondExpected = testTarget\n",
    "secondPredicted = model.predict(testData)\n",
    "\n",
    "# Calculando acurácia\n",
    "accuracy = accuracy_score(secondExpected, secondPredicted)\n",
    "print('Accuracy: {0}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "\n",
    "#### 3.1 Análise de acurácia das duas metodologias\n",
    "\n",
    "Em nossos testes, a acurácia se manteve no intervalo 64-76 para ambos algoritmos. Entretanto, vimos a segunda técnica ter um desempenho ligeiramente melhor, tendo, na maioria dos casos, a acurácia superior a 70. Por outro lado, a primeira técnica possui maior inclinação a gerar resultados com acurácia abaixo de 70. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Exposição de métricas\n",
    "\n",
    "#### Abordagem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.67      0.80       409\n",
      "         2.0       0.52      0.81      0.63       117\n",
      "         3.0       0.18      1.00      0.31        21\n",
      "         4.0       0.00      0.00      0.00        24\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       571\n",
      "   macro avg       0.42      0.62      0.43       571\n",
      "weighted avg       0.83      0.68      0.71       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(firstExpected, firstPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abordagem 2 (com sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.89      0.84      0.87       403\n",
      "         2.0       0.53      0.24      0.33       117\n",
      "         3.0       0.46      0.21      0.29        29\n",
      "         4.0       0.18      1.00      0.30        22\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       571\n",
      "   macro avg       0.52      0.57      0.45       571\n",
      "weighted avg       0.77      0.69      0.71       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(secondExpected, secondPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_Bayes_Trabalho.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
